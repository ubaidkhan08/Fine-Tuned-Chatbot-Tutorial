{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1d6d2a6",
   "metadata": {},
   "source": [
    "## Reading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "809eba22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "question  =[]\n",
    "answer = []\n",
    "with open(\"dialogs.txt\",'r') as f :\n",
    "    for line in f :\n",
    "        line  =  line.split('\\t')\n",
    "        question.append(line[0])\n",
    "        answer.append(line[1])\n",
    "print(len(question) == len(answer))\n",
    "\n",
    "result = pd.DataFrame({\"question\" : question ,\"answer\":answer})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1594d029",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555e0790",
   "metadata": {},
   "source": [
    "## Supervised Learning Approach \n",
    "`This approach trains a machine learning model that uses a pipeline of CountVectorizer, TfidfTransformer, and RandomForestClassifier to predict answers to questions.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8678589e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You: hi, how are you doing?\n",
      "Bot: i'm fine. how about yourself?\n",
      "\n",
      "You: i'm pretty good. thanks for asking.\n",
      "Bot: no problem. so how have you been?\n",
      "\n",
      "You: i've been good. i'm in school right now.\n",
      "Bot: what school do you go to?\n",
      "\n",
      "Interrupted by user\n",
      "You: hi\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# load the dataset\n",
    "df = result.head(100)\n",
    "\n",
    "# create a pipeline that consists of a CountVectorizer, a TfidfTransformer, and a RandomForestClassifier\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# fit the pipeline to the text data\n",
    "pipeline.fit(df['question'], df['answer'])\n",
    "\n",
    "# test the model\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input('You: ')\n",
    "        if user_input.lower() == 'quit':\n",
    "            break\n",
    "        response = pipeline.predict([user_input])[0]\n",
    "        print('Bot:', response)\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted by user\")\n",
    "        break    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd4d5ec",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85521da",
   "metadata": {},
   "source": [
    "## Unsupervised Learning Approach\n",
    "`This code builds a simple chatbot that uses a TF-IDF (term frequencyâ€“inverse document frequency) vectorization model to calculate the similarity between the user's input and the questions in the dataset. It loads a dataset of questions and answers, initializes a lemmatizer to normalize the text, tokenizes and lemmatizes the text, fits a TfidfVectorizer to the text data, transforms the text data into a tf-idf matrix, and creates a dictionary with question-answer pairs.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d74ecb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You: hi, how are you doing?\n",
      "Bot: i'm fine. how about yourself?\n",
      "\n",
      "You: i'm pretty good. thanks for asking.\t\n",
      "Bot: no problem. so how have you been?\n",
      "\n",
      "Interrupted by user\n",
      "You: Chat ended.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# load the dataset\n",
    "df =  result\n",
    "\n",
    "# initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# tokenize and lemmatize the text\n",
    "def tokenize_and_lemmatize(text):\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return lemmatized_tokens\n",
    "\n",
    "# create a TfidfVectorizer object\n",
    "vectorizer = TfidfVectorizer(tokenizer=tokenize_and_lemmatize)\n",
    "\n",
    "# fit the vectorizer to the text data\n",
    "vectorizer.fit(df['question'])\n",
    "\n",
    "# transform the text data to a tf-idf matrix\n",
    "tfidf_matrix = vectorizer.transform(df['question'])\n",
    "\n",
    "# create a dictionary with question-answer pairs\n",
    "qa_dict = dict(zip(df['question'], df['answer']))\n",
    "\n",
    "# define a function to generate responses\n",
    "def generate_response(user_input):\n",
    "    # transform the user input to a tf-idf vector\n",
    "    user_tfidf = vectorizer.transform([user_input])\n",
    "    # calculate the cosine similarities between the user input and the questions in the dataset\n",
    "    similarities = cosine_similarity(user_tfidf, tfidf_matrix)\n",
    "    # get the index of the question with the highest similarity\n",
    "    index = similarities.argmax()\n",
    "    # get the corresponding answer from the qa_dict\n",
    "    response = qa_dict[df.iloc[index]['question']]\n",
    "    return response\n",
    "\n",
    "# test the chatbot\n",
    "while True:\n",
    "    try: \n",
    "        user_input = input('You: ')\n",
    "        if user_input.lower() == 'quit':\n",
    "            break\n",
    "        response = generate_response(user_input)\n",
    "        print('Bot:', response)\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted by user\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fa46c9",
   "metadata": {},
   "source": [
    "## Thank you for your time!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
